import logging
import re
import os
import sys
from threading import Thread, Lock as ThreadLock
from dotenv import load_dotenv

# Lightweight Agent Framework
from smolagents import CodeAgent, Tool, InferenceClientModel, ChatMessage, MessageRole, ChatMessageStreamDelta, ActionStep, ToolCall, ToolOutput, FinalAnswerStep
from smolagents.models import get_clean_message_list
import smolagents.utils as smolagents_utils

# API Client for Vision & Chat
from huggingface_hub import InferenceClient

# Load environment variables
load_dotenv()
hf_token = os.getenv("HUGGINGFACE_API_KEY")

logger = logging.getLogger(__name__)

# ------------------------------------------------------------------
# SECURITY SANDBOX & FILE SYSTEM WRAPPERS
# ------------------------------------------------------------------

def get_desktop_path():
    from pathlib import Path
    return Path(r"C:\Users\nihan\Desktop")

def safe_write(filename: str, content: str) -> str:
    """Safely writes content to a file on the Desktop."""
    desktop = get_desktop_path()
    filename = filename.lstrip("/").lstrip("\\")
    filepath = (desktop / filename).resolve()
    
    if not str(filepath).startswith(str(desktop.resolve())):
        raise ValueError(f"Security Block (Path Traversal): {filename}")
        
    filepath.parent.mkdir(parents=True, exist_ok=True)
    filepath.write_text(content, encoding='utf-8')
    return str(filepath)

def safe_open(filepath_str, mode='r', **kwargs):
    """Safe wrapper for open() rooted to Desktop."""
    from pathlib import Path
    import builtins
    desktop = get_desktop_path()
    filepath = Path(filepath_str)
    
    if not filepath.is_absolute():
        filepath = desktop / filepath
    filepath = filepath.resolve()
    
    if any(m in mode for m in ('w', 'a', 'x')) and not str(filepath).startswith(str(desktop.resolve())):
        raise ValueError(f"Security Block (Write Outside Sandbox): {filepath}")
        
    if any(m in mode for m in ('w', 'a', 'x')):
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
    return builtins.open(str(filepath), mode, **kwargs)

def safe_mkdir(path_str, *args, **kwargs):
    """Safe wrapper for directory creation rooted to Desktop."""
    from pathlib import Path
    desktop = get_desktop_path()
    path = Path(path_str)
    
    if not path.is_absolute():
        path = desktop / path
    path = path.resolve()
    
    if not str(path).startswith(str(desktop.resolve())):
        raise ValueError(f"Security Block (mkdir Outside Sandbox): {path}")
    
    path.mkdir(parents=True, exist_ok=True)
    return str(path)

def open_in_browser(filepath_str):
    """Opens a file in the default web browser (Desktop rooted)."""
    import webbrowser as wb
    from pathlib import Path
    desktop = get_desktop_path()
    filepath = Path(filepath_str)
    
    if not filepath.is_absolute():
        filepath = desktop / filepath
    filepath = filepath.resolve()
    
    wb.open(filepath.as_uri())
    return str(filepath)

def create_web_page(folder_name: str, page_type: str = "landing", title: str = "My Page", theme: str = "dark") -> str:
    """
    Generates professional HTML/CSS templates for standard pages.
    """
    folder_path = safe_mkdir(folder_name)
    from pathlib import Path
    folder = Path(folder_path)
    
    bg = "#0f0f1a" if theme == "dark" else "#f0f2f5"
    text = "#e0e0e0" if theme == "dark" else "#333333"
    accent = "#6c63ff"
    
    html_content = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>{title}</title>
    <style>
        body {{ background: {bg}; color: {text}; font-family: sans-serif; display: flex; justify-content: center; align-items: center; height: 100vh; margin: 0; }}
        .container {{ text-align: center; padding: 40px; border: 1px solid {accent}; border-radius: 10px; }}
        h1 {{ color: {accent}; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>{title}</h1>
        <p>Generated by Omni-Agent Studio ({page_type})</p>
    </div>
</body>
</html>"""

    (folder / "index.html").write_text(html_content, encoding='utf-8')
    return open_in_browser(str(folder / "index.html"))

# ------------------------------------------------------------------
# CODE CLEANER & MONKEY PATCHES
# ------------------------------------------------------------------

def clean_code_output(code: str) -> str:
    lines = code.split('\n')
    cleaned = []
    for line in lines:
        stripped = line.strip()
        if stripped.startswith('Thought:') or stripped.startswith('Code:') or re.match(r'^\d+\.\s+[A-Z]', stripped):
            continue
        cleaned.append(line)
    
    result = '\n'.join(cleaned).strip()
    if not result:
        return code
        
    if 'final_answer' not in result:
        result += '\nfinal_answer("Done!")'
    return result

_original_parse_code_blobs = smolagents_utils.parse_code_blobs
def _patched_parse_code_blobs(text: str, code_block_tags: tuple) -> str:
    try:
        code = _original_parse_code_blobs(text, code_block_tags)
        return clean_code_output(code)
    except ValueError:
        raise

smolagents_utils.parse_code_blobs = _patched_parse_code_blobs
try:
    import smolagents.agents as smolagents_agents
    smolagents_agents.parse_code_blobs = _patched_parse_code_blobs
except Exception:
    pass

# ------------------------------------------------------------------
# VISION TOOL (SERVERLESS)
# ------------------------------------------------------------------

class VisionTool(Tool):
    name = "analyze_screen"
    description = "Analyze the latest screen frame to answer a question. Use this tool when the user asks you to 'see', 'look', or describe what is on the screen."
    inputs = {
        "question": {
            "type": "string",
            "description": "The question to ask about the screen content (e.g., 'What do you see?', 'Read the error')."
        }
    }
    output_type = "string"

    def __init__(self, get_image_func, **kwargs):
        super().__init__(**kwargs)
        self.get_image_func = get_image_func
        # Use Hugging Face Inference API for Vision
        self.client = InferenceClient(token=os.getenv("HUGGINGFACE_API_KEY"))

    def forward(self, question: str) -> str:
        try:
            image_data = self.get_image_func()
            if not image_data:
                return "No screen frame available. Ask the user to verify screen sharing is on."
            
            # Clean base64 string
            if "," in image_data:
                 image_data = image_data.split(",")[1]
            
            logger.info(f"VisionTool: Analyzing screen with question: '{question}' (Cloud Vision)")
            
            # Use Qwen2.5-VL-7B-Instruct or Llama-3.2-11B-Vision
            # Trying Qwen/Qwen2.5-VL-7B-Instruct first as it matches our Coder model family
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}},
                        {"type": "text", "text": question}
                    ]
                }
            ]
            
            response = self.client.chat_completion(
                model="Qwen/Qwen2.5-VL-7B-Instruct",
                messages=messages,
                max_tokens=500
            )
            
            result = response.choices[0].message.content
            logger.info(f"VisionTool Result: {result[:50]}...")
            return f"Screen Insight: {result}"
            
        except Exception as e:
            logger.error(f"VisionTool Error: {e}")
            return f"Error analyzing screen: {str(e)}"

# ------------------------------------------------------------------
# OMNI AGENT (CLOUD BRAIN)
# ------------------------------------------------------------------

class OmniAgent:
    def __init__(self):
        logger.info("Initializing Cloud Brain (Qwen2.5-Coder-32B)...")
        
        if not hf_token:
            logger.error("CRITICAL: HUGGINGFACE_API_KEY missing!")
        
        try:
            self.model = InferenceClientModel(
                model_id="Qwen/Qwen2.5-Coder-32B-Instruct",
                token=hf_token
            )
            
            # Vision Caching
            self.image_lock = ThreadLock()
            self.latest_image = None
            
            def get_latest_image():
                with self.image_lock:
                    return self.latest_image
            
            self.vision_tool = VisionTool(get_latest_image)
            
            # PROMPT: Enforcing Sandbox & Vision & Persona
            SYSTEM_PROMPT = r"""
You are a Senior Python Developer and AI Assistant, created by Nihan Nihu.
If asked "Who created you?", always answer "I was created by Nihan Nihu."

RULES:
1. **Security**: SANDBOXED. No `os`, `subprocess`. Only Desktop access.
2. **Tools**:
   - `safe_write`, `safe_mkdir`, `safe_open` for files.
   - `analyze_screen(question)`: Call this to SEE the user's screen!
   - `create_web_page(...)`: Use for generic pages.
3. **Coding**:
   - For CUSTOM sites, write HTML/CSS manually using `safe_write`.
   - Always end with `final_answer(variable)`.

EXAMPLE (Vision):
Thought: User asked what's on screen.
```python
description = analyze_screen("Describe the UI layout")
final_answer(description)
```
"""
            self.agent = CodeAgent(
                tools=[self.vision_tool], 
                model=self.model, 
                add_base_tools=True,
                max_steps=5, 
                verbosity_level=logging.INFO,
                instructions=SYSTEM_PROMPT,
                additional_authorized_imports=["datetime", "math", "random", "time", "json", "re"],
                stream_outputs=True,
                executor_kwargs={
                    "additional_functions": {
                        "safe_write": safe_write,
                        "safe_open": safe_open,
                        "safe_mkdir": safe_mkdir,
                        "open_in_browser": open_in_browser,
                        "create_web_page": create_web_page,
                        "VisionTool": VisionTool # expose class if needed by smolagents internals? likely not
                    }
                }
            )
            logger.info("Cloud Brain initialized successfully.")
            
        except Exception as e:
            logger.error(f"Failed to initialize AI Agent: {e}")
            raise e

    def update_vision_context(self, base64_image: str):
        with self.image_lock:
            # logger.debug("Updated latest screen frame")
            self.latest_image = base64_image

    def execute_stream(self, task: str):
        logger.info(f"Agent thinking on task: {task}")
        try:
            for step in self.agent.run(task, stream=True):
                # logger.info(f"Stream Step: {type(step)}")
                
                if isinstance(step, ChatMessageStreamDelta):
                    if step.content:
                        yield step.content
                elif isinstance(step, ToolCall):
                    yield f"\n> Executing tool: {step.name}...\n"
                elif hasattr(step, "observation") and step.observation:
                    yield f"\nObservation:\n{step.observation}\n"
                elif isinstance(step, ActionStep):
                    if step.error:
                        yield f"\n[Error]: {step.error}\n"
                    if hasattr(step, "observations") and step.observations:
                         yield f"\nObservation:\n{step.observations}\n"
                    if step.is_final_answer and step.action_output is not None:
                        yield f"\nFinal Answer: {step.action_output}\n"
                elif isinstance(step, FinalAnswerStep):
                    yield f"\nFinal Answer: {step.output}\n"
                elif isinstance(step, ToolOutput): # Explicit check just in case
                    yield f"\nObservation:\n{step.observation}\n"
        except GeneratorExit:
            logger.info("Client disconnected.")
            return
        except Exception as e:
            logger.error(f"Execution Error: {e}")
            yield f"Error: {e}"
